---
title: 😖 相关系数与决定系数
comments: true
---


## 壹丨相关概念

> **皮尔逊积矩相关系数**（英语：**P**earson **p**roduct-**m**oment **c**orrelation **c**oefficient，缩写：**PPMCC**，或**PCCs**，有时简称**相关系数**）用于度量两组数据的变量X和Y之间的线性相关的程度。它是两个变量的协方差与其标准差的乘积之比； 因此，它本质上是协方差的归一化度量，因此结果始终具有介于-1和1之间的值。与协方差本身一样，该度量只能反映变量的线性相关性，而忽略了许多其他类型的关系或相关性。[^1]
>
> 举个简单的例子，可以预期高中青少年样本的年龄和身高的皮尔逊积矩相关系数显著大于0，但小于1（因为1表示不切实际的完美相关性）。

>**决定系数**，或称**判定系数**（英语：Coefficient of determination，记为*R2*或*r2*），在统计学中用于度量因变量的变异中可由自变量解释部分所占的比例，以此来判断回归模型的解释力。[^2]
>
>对于简单线性回归而言，决定系数为样本相关系数的平方。当加入其他回归自变量后，决定系数相应地变为多重相关系数的平方。

## 贰丨举个简单例子


```python
import numpy as np
from sklearn.metrics import r2_score

fake_true = np.random.random(100) * 50
fake_pred = fake_true + np.random.random(100) * 10

r = np.corrcoef(fake_pred, fake_true)[0][1]
r2 = r2_score(fake_true, fake_pred)
print(f'{r=}')
print(f'{r2=}')
print(f'r**2={r ** 2}')
```

```
r=0.9800127107917392
r2=0.8088416899303008
r**2=0.9604249133133731
```

## 叁丨相关系数和决定系数的区别

> 源自ChatGPT

相关系数（r）和决定系数（R²）是两种常用的统计量，用于衡量变量之间的关系和模型的拟合程度。它们有不同的特点和适用场景，因此在不同的情况下可能会选择使用其中之一。

相关系数（r）衡量的是两个变量之间的线性相关程度，取值范围在-1到1之间。当r接近1时，表示两个变量之间存在强正相关关系；当r接近-1时，表示两个变量之间存在强负相关关系；当r接近0时，表示两个变量之间不存在线性相关关系。相关系数可以帮助我们理解变量之间的线性关系，以及它们的方向和强度。

决定系数（R²）则是一种用于衡量回归模型对目标变量的解释能力的统计量。R²的取值范围是从0到1，表示模型能够解释目标变量变异性的比例。当R²接近1时，表示模型能够很好地解释目标变量的变异性；当R²接近0时，表示模型无法解释目标变量的变异性，即模型的拟合效果较差。R²可以帮助我们评估回归模型的性能和预测能力。

使用相关系数（r）的优点包括：

1. 相关系数可以帮助我们了解变量之间的线性关系，包括方向和强度。这对于探索数据中的关联和趋势非常有用。
2. 相关系数可以用于任何类型的变量，包括连续型、分类型和二元型变量。

使用决定系数（R²）的优点包括：

1. 决定系数可以直接反映模型对目标变量的解释能力，即模型能够解释目标变量变异性的比例。
2. 决定系数可以用于评估回归模型的性能和预测能力，帮助我们选择最佳的模型。

在实际应用中，选择使用相关系数（r）还是决定系数（R²）取决于具体的分析目的和问题背景。如果我们更关注变量之间的线性相关性，或者想要了解变量之间的方向和强度，那么相关系数更为合适。如果我们更关注回归模型的性能和预测能力，或者想要比较不同模型的解释能力，那么决定系数更为适用。

## 肆丨为什么sklearn输出的决定系数可以为负值？

决定系数（Coefficient of Determination），也称为R²分数，用于衡量回归模型对目标变量的解释能力。在scikit-learn（sklearn）中，r2_score是用于计算决定系数的函数之一。

决定系数的取值范围是从负无穷到1之间，其中1表示完美拟合，0表示模型无法解释目标变量的变异性，而负数表示模型的表现比直接使用均值预测还要差。

当决定系数为负数时，表示模型对目标变量的解释能力非常差，甚至比使用简单的均值预测还要差。这可能发生在回归模型的拟合过程中，当模型的预测结果远离实际观测值时，导致模型的解释能力变得负面。

负的决定系数可能是由于以下原因之一：
1. 模型选择不当：选用的回归模型可能不适合解释目标变量的变异性，或者模型中的特征选择不当。
2. 数据误差：数据中存在噪声或异常值，导致模型无法准确地拟合数据。
3. 过拟合：模型过于复杂，过度拟合了训练数据，导致在未知数据上的表现较差。

当计算决定系数时，sklearn的r2_score函数会返回负数，以提醒用户模型的表现不佳。在实际应用中，通常希望决定系数为正值，接近1越好，但在某些情况下，负的决定系数也可能提供一些有价值的信息，例如表示模型的预测比基准（如均值）更差。

因此，在使用r2_score函数计算决定系数时，负数的结果应被视为模型性能的警示信号，需要进一步分析和改进模型以提高性能。



[^1]: @维基百科，[皮尔逊积矩相关系数](https://zh.wikipedia.org/wiki/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%A7%AF%E7%9F%A9%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0)
[^2]: @维基百科，[决定系数](https://zh.wikipedia.org/wiki/%E5%86%B3%E5%AE%9A%E7%B3%BB%E6%95%B0)
